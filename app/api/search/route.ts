import { NextRequest, NextResponse } from "next/server"
import { PrismaClient } from "@prisma/client"
import { callChatGPT } from "@/lib/openai"
import { genAI } from "@/lib/gemini"


const prisma = new PrismaClient()


function log(msg: string) {
    console.log(msg);
}

export async function POST(req: NextRequest) {
    try {
        const { query, fileData, fileType } = await req.json()
        log(`[Search API] Query: "${query}"`);
        if (fileData) {
            log(`[Search API] File attached: ${fileType}`);
        }

        if (!query) {
            return NextResponse.json({ solutions: [] })
        }

        // 1. Search in Database (only if no file attached)
        if (!fileData) {
            const solutions = await prisma.solution.findMany({
                where: {
                    OR: [
                        { title: { contains: query } },
                        { keywords: { contains: query } },
                        { description: { contains: query } }
                    ]
                },
                take: 3
            })
            log(`[Search API] DB Search found ${solutions.length} solutions.`);

            // 2. If found, return results
            if (solutions.length > 0) {
                return NextResponse.json({ solutions })
            }
        }

        // 3. If NOT found or has file, use AI
        const appSettings = await prisma.settings.findFirst()
        const enableAI = appSettings?.enableAiSearch ?? (process.env.ENABLE_AI_SEARCH === 'true');
        log(`[Search API] AI Enabled: ${enableAI}`);

        if (enableAI) {
            try {
                if (!genAI) {
                    log("Gemini API Key is missing.");
                    return NextResponse.json({ solutions: [] });
                }

                log("Initializing Gemini model...");
                // Using Gemini 3.0 Flash - supports multimodal
                const model = genAI.getGenerativeModel({ model: "gemini-3-flash-preview" });

                const textPrompt = `B·∫°n l√† k·ªπ thu·∫≠t vi√™n robot GIHO. Tr·∫£ l·ªùi NG·∫ÆN G·ªåN nh∆∞ nh·∫Øn tin, t·ªëi ƒëa 3-4 d√≤ng.

${fileData ? `Kh√°ch g·ª≠i ${fileType === 'image' ? '·∫£nh' : 'video'}. Ph√¢n t√≠ch ngay v√† ƒë∆∞a gi·∫£i ph√°p c·ª• th·ªÉ.` : ''}

Kh√°ch: "${query}"

Quy t·∫Øc:
- ƒê√£ ƒë·ªß th√¥ng tin: ƒë∆∞a gi·∫£i ph√°p ngay (t·ªëi ƒëa 3 b∆∞·ªõc ng·∫Øn)
- Ch∆∞a ƒë·ªß th√¥ng tin: h·ªèi 1 c√¢u ng·∫Øn NH·∫§T, ∆∞u ti√™n h·ªèi "B·∫°n c√≥ th·ªÉ g·ª≠i ·∫£nh/video kh√¥ng?" n·∫øu ch∆∞a r√µ
- KH√îNG ch√†o h·ªèi, KH√îNG gi·∫£i th√≠ch d√†i d√≤ng, KH√îNG h·ªèi nhi·ªÅu c√¢u c√πng l√∫c`;

                log("[Search API] Sending prompt to Gemini...");

                // Add timeout for Gemini (45 seconds)
                const geminiPromise = (async () => {
                    if (fileData && fileType) {
                        const parts: any[] = [{ text: textPrompt }];
                        if (fileType === 'image') {
                            parts.push({ inlineData: { mimeType: fileData.mimeType, data: fileData.base64 } });
                        } else if (fileType === 'video') {
                            parts.push({ inlineData: { mimeType: fileData.mimeType, data: fileData.base64 } });
                        }
                        return await model.generateContent(parts);
                    } else {
                        return await model.generateContent(textPrompt);
                    }
                })();

                const timeoutPromise = new Promise((_, reject) => {
                    setTimeout(() => reject(new Error('Gemini timeout after 45 seconds')), 45000);
                });

                const result = await Promise.race([geminiPromise, timeoutPromise]) as any;
                const response = result.response;
                const text = response.text();
                log("[Search API] Gemini response received.");

                // Return as a special AI solution
                return NextResponse.json({
                    solutions: [{
                        id: 'ai-generated',
                        title: fileData ? 'ü§ñ Ph√¢n t√≠ch t·ª´ AI (D·ª±a tr√™n ·∫£nh/video)' : 'üí° G·ª£i √Ω t·ª´ AI (Ph√¢n t√≠ch t·ª± ƒë·ªông)',
                        description: text,
                        videoUrl: null,
                        keywords: 'ai, auto-generated',
                        updatedAt: new Date(),
                        createdAt: new Date()
                    }]
                })

            } catch (aiError: any) {
                log(`AI Generation Error: ${aiError?.message || aiError}`);

                // Try ChatGPT as fallback
                try {
                    log("[Search API] AI failed, trying ChatGPT fallback...");

                    const chatGPTPrompt = `
                    B·∫°n l√† k·ªπ thu·∫≠t vi√™n chuy√™n s·ª≠a robot h√∫t b·ª•i GIHO v·ªõi 10 nƒÉm kinh nghi·ªám.
                    
                    NG·ªÆ C·∫¢NH CU·ªòC TR√í CHUY·ªÜN:
                    ${query}
                    
                    NHI·ªÜM V·ª§ C·ª¶A B·∫†N:
                    1. N·∫æU CH∆ØA R√ï V·∫§N ƒê·ªÄ: H·ªèi l·∫°i kh√°ch h√†ng c·ª• th·ªÉ
                    2. N·∫æU ƒê√É R√ï: Ch·∫©n ƒëo√°n CH√çNH X√ÅC d·ª±a tr√™n tri·ªáu ch·ª©ng ‚Üí ƒê∆∞a gi·∫£i ph√°p C·ª§ TH·ªÇ
                    
                    Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ng·∫Øn g·ªçn, th√¢n thi·ªán.
                    `;

                    const chatGPTResponse = await callChatGPT(chatGPTPrompt, fileData, fileType);
                    log("[Search API] ChatGPT response received.");

                    return NextResponse.json({
                        solutions: [{
                            id: 'ai-generated',
                            title: fileData ? 'ü§ñ Ph√¢n t√≠ch t·ª´ AI (D·ª±a tr√™n ·∫£nh/video)' : 'üí° G·ª£i √Ω t·ª´ AI (Ph√¢n t√≠ch t·ª± ƒë·ªông)',
                            description: chatGPTResponse,
                            videoUrl: null,
                            keywords: 'ai, auto-generated, chatgpt',
                            updatedAt: new Date(),
                            createdAt: new Date()
                        }]
                    });
                } catch (chatGPTError: any) {
                    log(`ChatGPT also failed: ${chatGPTError?.message || chatGPTError}`);
                    // Both AI failed, escalate to technician
                    return NextResponse.json({
                        solutions: [{
                            id: 'need-technician',
                            title: 'C·∫ßn k·ªπ thu·∫≠t vi√™n h·ªó tr·ª£',
                            description: 'H·ªá th·ªëng AI t·∫°m th·ªùi kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n.',
                            videoUrl: null,
                            keywords: 'escalate, technician',
                            updatedAt: new Date(),
                            createdAt: new Date()
                        }]
                    });
                }
            }
        }

        return NextResponse.json({ solutions: [] })

    } catch (error: any) {
        log(`Internal Error: ${error?.message || error}`);
        return NextResponse.json({ error: "Internal Error" }, { status: 500 })
    }
}
